{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<b>CompEcon Toolbox:</b>\n",
    "<div style=\"font-size:175%;color:white; background-color: #0064b0;\">DemApp00</div>\n",
    "<div style=\"font-size:250%;color:white; background-color: #0064b0;\">Approximating using the CompEcon toolbox</div>\n",
    "\n",
    "<b>Randall Romero Aguilar, PhD</b>\n",
    "<br><br>\n",
    "\n",
    "</center>\n",
    "\n",
    "This demo is based on the original Matlab demo accompanying the  <a href=\"https://mitpress.mit.edu/books/applied-computational-economics-and-finance\">Computational Economics and Finance</a> 2001 textbook by Mario Miranda and Paul Fackler.\n",
    "\n",
    "\n",
    "<i>Last updated: 2020-Sep-08</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"This notebook is running on Google Colab. Installing the compecon package.\")\n",
    "    !pip install compecon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from compecon import BasisChebyshev,nodeunif\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximating the function $f(x) = e^{-2x}$. Its derivative is $f'(x) = -2e^{-2x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda x: np.exp(-2 * x)\n",
    "d1 = lambda x: -2 * np.exp(-2 * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit approximant\n",
    "\n",
    "The CompEcon toolbox defines the ```BasisChebyshev``` class for Chebyshev interpolation. Its positional arguments are `n` (number of nodes), `a` (lower bound) and `b` (upper bound). The optional keyword argument `f` indicates a function (the lambda `f1` in our example) to be approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, a, b = 10, -1, 1\n",
    "f1fit = BasisChebyshev(n, a, b, f=f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `f1fit` is an instance of the `BasisChebyshev` class. Once a function is specified (as with the keyword argument `f` above), it can be evaluated at a given vector `x` by *calling* `f1fit`  as any other function\n",
    "```\n",
    "f1fit(x)  # returns a vector containing the interpolation of each element of x\n",
    "f1fit()   # without arguments, it evaluates the function at the basis nodes\n",
    "```\n",
    "\n",
    "When a function is specified with the option `f`, the `BasisChebyshev` object computes the interpolation coefficients $c = \\Phi(x)^{-1}f(x)$, where $x$ represent the nodes of bhe basis.  Alternatively, if the values `fx` of the function at the nodes are available (instead of the function itself, as is usually the case), then the basis is created by:\n",
    "```\n",
    "BasisChebyshev(n, a, b, y=fx)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph approximation error for function and derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the precission of the interpolation, we compare the the fitted function `f1fit` to the true values `f1` over a grid of 1001 points. We do the same for the derivative function.\n",
    "\n",
    "In the figures, the red dots represent the 10 interpolation nodes (where residuals equal zero, by construction). These are returned by the `.nodes` attribute of the basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axopts = {'xlabel': 'x', 'ylabel': 'Error', 'xticks': [-1, 0, 1]}\n",
    "x = np.linspace(a, b, 1001)\n",
    "fig = plt.figure(figsize=[12, 6])\n",
    "\n",
    "ax1 = fig.add_subplot(121, title='Function approximation error', **axopts)\n",
    "ax1.axhline(linestyle='--', color='gray', linewidth=2)\n",
    "ax1.plot(f1fit.nodes, np.zeros_like(f1fit.nodes), 'ro', markersize=12)\n",
    "ax1.plot(x, f1fit(x) - f1(x))\n",
    "\n",
    "ax2 = fig.add_subplot(122, title='Derivative approximation error', **axopts)\n",
    "ax2.plot(x, np.zeros_like(x), '--', color='gray', linewidth=2)\n",
    "ax2.plot(f1fit.nodes, np.zeros_like(f1fit.nodes), 'ro', markersize=12)\n",
    "ax2.plot(x, f1fit(x, 1) - d1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximating the function $f(x_1, x_2) = \\dfrac{\\cos(x_1)}{e^{x_2}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = lambda x: np.cos(x[0]) / np.exp(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set degree and domain interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```BasisChebyshev``` class can also interpolate *d*-dimensional functions. If one of the positional arguments is a scalar (like the bounds below), it is assumed that the same value holds in every dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, a, b = 7, 0.0, 1.0\n",
    "f2fit = BasisChebyshev([n, n], a, b, f=f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, multidimensional interpolation is done by taking the tensor product of each dimension. Other options are available with the keyword `method`, as in:\n",
    "```\n",
    "BasisChebyshev(n, a, b, method='smolyak', qn=3, qp= 3) # for Smolyak interpolation\n",
    "BasisChebyshev(n, a, b, method='complete', qp=2)       # for complete polynomials\n",
    "BasisChebyshev(n, a, b, method='tensor')               # tensor product (default)\n",
    "```\n",
    "\n",
    "Notice that Smolyak and complete polynomials interpolation require the setting of keywords `qn` and `qp`, to control node and polynomial selection, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice plot of function approximation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the residuals over a 101 by 101 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplot = [101, 101]\n",
    "x = nodeunif(nplot, a, b)\n",
    "x1, x2 = x\n",
    "error = f2fit(x) - f2(x)\n",
    "error.shape = nplot\n",
    "x1.shape = nplot\n",
    "x2.shape = nplot\n",
    "\n",
    "fig = plt.figure(figsize=[15, 6])\n",
    "ax = fig.gca(projection='3d', title='Chebyshev Approximation Error',\n",
    "             xlabel='$x_1$', ylabel='$x_2$', zlabel='Error')\n",
    "ax.plot_surface(x1, x2, error, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                linewidth=0, antialiased=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial derivatives can be computed by *calling* a `BasisChebyshev` object, indicating the order of derivatives by a second argument `order`, as in\n",
    "```\n",
    "f2fit(x, order)\n",
    "```\n",
    "\n",
    "Notice that unlike the MATLAB version of CompEcon, in this Python version the first index of `x` indicates the dimension, while the last index indicates an \"observation\" (evaluation point). Something similar applies to the `order` parameter: `order[i, j]` indicates the order of differentiation with respect to `i` in evaluation `j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.5], [0.5]])\n",
    "order = [[1, 0, 2, 1, 0],\n",
    "         [0, 1, 0, 1, 2]]\n",
    "\n",
    "ff = f2fit(x, order)\n",
    "\n",
    "print(('x   = [0.5, 0.5]\\n' + \n",
    "       'f1  = {:7.4f}\\n' + \n",
    "       'f2  = {:7.4f}\\n' + \n",
    "       'f11 = {:7.4f}\\n' +\n",
    "       'f12 = {:7.4f}\\n' +\n",
    "       'f22 = {:7.4f}').format(*ff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
